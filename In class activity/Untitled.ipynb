{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "import nltk, re, pprint\n",
    "import numpy as np\n",
    "\n",
    "#nltk.download() #download NLTK repositories\n",
    "#sudo apt-get install python3-pil.imagetk #install for tree visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noun Phrase Chunking\n",
    "\n",
    "sentence = [(\"the\", \"DT\"), (\"little\", \"JJ\"), (\"yellow\", \"JJ\"),\n",
    "            (\"dog\", \"NN\"), (\"barked\", \"VBD\"), (\"at\", \"IN\"),\n",
    "            (\"the\", \"DT\"), (\"cat\", \"NN\")]\n",
    "\n",
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "\n",
    "#This rule says that an NP chunk should be formed whenever the chunker\n",
    "#finds an optional determiner (DT) followed by any number of \n",
    "#adjectives (JJ) and then a noun (NN).\n",
    "\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "result = cp.parse(sentence)\n",
    "print(result)\n",
    "result.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chunk structure for a sentence\n",
    "\n",
    "grammar = r\"\"\"\n",
    "  NP: {<DT|PP\\$>?<JJ>*<NN>}   # chunk determiner/possessive, adjectives and noun\n",
    "      {<NNP>+}                # chunk sequences of proper nouns\n",
    "\"\"\"\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "\n",
    "#The first rule matches an optional determiner or possessive pronoun, \n",
    "#zero or more adjectives, then a noun. The second rule matches \n",
    "#one or more proper nouns.\n",
    "\n",
    "\n",
    "sentence = [(\"Rapunzel\", \"NNP\"), (\"let\", \"VBD\"), (\"down\", \"RP\"),\n",
    "            (\"her\", \"PP$\"), (\"long\", \"JJ\"), (\"golden\", \"JJ\"), \n",
    "            (\"hair\", \"NN\")]\n",
    "\n",
    "print(cp.parse(sentence))\n",
    "cp.parse(sentence).draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import treebank\n",
    "t = treebank.parsed_sents('wsj_0001.mrg')[0]\n",
    "print (t)\n",
    "t.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract phrases matching a particular sequence of part-of-speech tags\n",
    "\n",
    "cp = nltk.RegexpParser('CHUNK: {<V.*> <TO> <V.*>}')\n",
    "brown = nltk.corpus.brown\n",
    "for sent in brown.tagged_sents():\n",
    "# for sent in treebank.tagged_sents():\n",
    "    tree = cp.parse(sent)\n",
    "    for subtree in tree.subtrees():\n",
    "        if subtree.label() == 'CHUNK':\n",
    "            print(subtree)\n",
    "\n",
    "            \n",
    "#Trying finding other phrases that uses to-infinitive:\n",
    "\n",
    "#Nouns with to-infinitives {happy to come; surprised to see}\n",
    "#Adjectives with to-infinitives {an opportunity to escape, need to shout}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(NP Alice)\n",
      "(NP the rabbit)\n",
      "(S (NP Alice) (VP chased (NP the rabbit)))\n"
     ]
    }
   ],
   "source": [
    "tree1 = nltk.Tree('NP', ['Alice'])\n",
    "print(tree1)\n",
    "tree1.draw()\n",
    "\n",
    "tree2 = nltk.Tree('NP', ['the', 'rabbit'])\n",
    "print(tree2)\n",
    "tree2.draw()\n",
    "\n",
    "tree3 = nltk.Tree('VP', ['chased', tree2])\n",
    "tree3.draw()\n",
    "\n",
    "tree4 = nltk.Tree('S', [tree1, tree3])\n",
    "print(tree4)\n",
    "tree4.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(NP (JJ small) (NNS (NNS cats) (CC and) (NNS mice)))\n",
      "(NP (NP (JJ small) (NNS cats)) (CC and) (NP (NNS mice)))\n"
     ]
    }
   ],
   "source": [
    "from nltk import CFG,ChartParser\n",
    "grammar=CFG.fromstring('''\n",
    "        NP -> NNS|JJ NNS|NP CC NP\n",
    "        NNS -> \"cats\"|\"dogs\"|\"mice\"|NNS CC NNS \n",
    "        JJ -> \"big\"|\"small\"\n",
    "        CC -> \"and\"|\"or\"\n",
    "        ''')\n",
    "\n",
    "parser=ChartParser(grammar)\n",
    "\n",
    "sent = 'small cats and mice'\n",
    "tokens = sent.split()\n",
    "\n",
    "parse=parser.parse(tokens)\n",
    "\n",
    "# print parse\n",
    "\n",
    "for tree in parse:\n",
    "        print(tree)\n",
    "        #tree.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (VP (V shot) (NP (Det an) (N elephant)))\n",
      "    (PP (P in) (NP (Det my) (N pajamas)))))\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (V shot)\n",
      "    (NP (Det an) (N elephant) (PP (P in) (NP (Det my) (N pajamas))))))\n"
     ]
    }
   ],
   "source": [
    "groucho_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    PP -> P NP\n",
    "    NP -> Det N | Det N PP | 'I'\n",
    "    VP -> V NP | VP PP\n",
    "    Det -> 'an' | 'my'\n",
    "    N -> 'elephant' | 'pajamas'\n",
    "    V -> 'shot'\n",
    "    P -> 'in'\n",
    "    \"\"\")\n",
    "\n",
    "sent = \"I shot an elephant in my pajamas\"\n",
    "tokens = sent.split()\n",
    "parser = nltk.ChartParser(groucho_grammar)\n",
    "for tree in parser.parse(tokens):\n",
    "    print(tree)\n",
    "    #tree.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP John)\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP (Det the) (N cat))\n",
      "    (PP (P with) (NP (Det a) (N dog)))))\n",
      "(S\n",
      "  (NP John)\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP (Det the) (N cat) (PP (P with) (NP (Det a) (N dog))))))\n"
     ]
    }
   ],
   "source": [
    "grammar1 = nltk.CFG.fromstring(\"\"\"\n",
    "  S -> NP VP\n",
    "  VP -> V NP | V NP PP\n",
    "  PP -> P NP\n",
    "  V -> \"saw\" | \"ate\" | \"walked\"\n",
    "  NP -> \"John\" | \"Mary\" | \"Bob\" | Det N | Det N PP\n",
    "  Det -> \"a\" | \"an\" | \"the\" | \"my\"\n",
    "  N -> \"man\" | \"dog\" | \"cat\" | \"telescope\" | \"park\"\n",
    "  P -> \"in\" | \"on\" | \"by\" | \"with\"\n",
    "  \"\"\")\n",
    "\n",
    "# sent = \"Mary saw Bob\"\n",
    "# sent = \"John saw Bob with a dog\"\n",
    "sent = \"John saw the cat with a dog\"\n",
    "# sent = \"the dog saw a man in the park\"\n",
    "tokens = sent.split()\n",
    "\n",
    "#Parsing algorithm\n",
    "\n",
    "parser = nltk.ChartParser(grammar1)\n",
    "\n",
    "trees = []\n",
    "for tree in parser.parse(tokens):\n",
    "    print(tree)\n",
    "    trees.append(tree)\n",
    "tree.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To compare multiple trees in a single window, we can use the \n",
    "#draw_trees() method\n",
    "\n",
    "from nltk.draw.tree import draw_trees\n",
    "\n",
    "draw_trees(trees[0], trees[1])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP (PropN Chatterer))\n",
      "  (VP\n",
      "    (V said)\n",
      "    (S\n",
      "      (NP (PropN Buster))\n",
      "      (VP\n",
      "        (V thought)\n",
      "        (S (NP (Det the) (Nom (N tree))) (VP (V was) (Adj tall)))))))\n"
     ]
    }
   ],
   "source": [
    "#Recursion\n",
    "\n",
    "grammar2 = nltk.CFG.fromstring(\"\"\"\n",
    "  S  -> NP VP\n",
    "  NP -> Det Nom | PropN\n",
    "  Nom -> Adj Nom | N\n",
    "  VP -> V Adj | V NP | V S | V NP PP\n",
    "  PP -> P NP\n",
    "  PropN -> 'Buster' | 'Chatterer' | 'Joe'\n",
    "  Det -> 'the' | 'a'\n",
    "  N -> 'bear' | 'squirrel' | 'tree' | 'fish' | 'log'\n",
    "  Adj  -> 'angry' | 'frightened' |  'little' | 'tall'\n",
    "  V ->  'chased'  | 'saw' | 'said' | 'thought' | 'was' | 'put'\n",
    "  P -> 'on'\n",
    "  \"\"\")\n",
    "\n",
    "# sent = \"the angry bear chased the frightened little squirrel\"\n",
    "sent = \"Chatterer said Buster thought the tree was tall\"\n",
    "tokens = sent.split()\n",
    "\n",
    "#Parsing algorithm\n",
    "\n",
    "# parser = nltk.RecursiveDescentParser(grammar2)\n",
    "# parser = nltk.ChartParser(grammar2)\n",
    "# parser = nltk.ChartParser(grammar2, trace=2)\n",
    "# parser = nltk.ShiftReduceParser(grammar2)\n",
    "parser = nltk.parse.BottomUpLeftCornerChartParser(grammar2)\n",
    "\n",
    "for tree in parser.parse(tokens):\n",
    "    print(tree)\n",
    "    tree.draw()\n",
    "\n",
    "\n",
    "#If the command print(tree) produces no output, this is probably \n",
    "#because your sentence sent is not admitted by your grammar.\n",
    "\n",
    "\n",
    "#To investigate call the parser with tracing set to be on...\n",
    "#You can also check what productions are currently in the grammar \n",
    "#with the command\n",
    "\n",
    "\n",
    "# for p in grammar2.productions():\n",
    "#     print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['show', 'me', 'northwest', 'flights', 'to', 'detroit', '.']\n"
     ]
    }
   ],
   "source": [
    "#Download <nltk.download('large_grammars')>\n",
    "\n",
    "#Reading the ATIS grammar\n",
    "\n",
    "grammar = nltk.data.load('grammars/large_grammars/atis.cfg')\n",
    "# print grammar\n",
    "\n",
    "#Reading the test sentences.\n",
    "\n",
    "sentences = nltk.data.load('grammars/large_grammars/atis_sentences.txt')\n",
    "sentences = nltk.parse.util.extract_test_sentences(sentences)\n",
    "# print sentences\n",
    "# print(len(sentences))\n",
    "\n",
    "testsentence = sentences[22]\n",
    "# print testsentence\n",
    "\n",
    "# print testsentence[0] #sentence\n",
    "# print testsentence[1] #number of parse trees according to grammar\n",
    "\n",
    "sentence = testsentence[0]\n",
    "print (sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28352\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "parser = nltk.parse.EarleyChartParser(grammar)\n",
    "\n",
    "chart = parser.chart_parse(sentence)\n",
    "\n",
    "#Return the final parse ``Chart`` from which all possible \n",
    "#parse trees can be extracted.\n",
    "\n",
    "print((chart.num_edges())) #edges number\n",
    "print((len(list(chart.parses(grammar.start()))))) #parse trees\n",
    "\n",
    "trees = list(chart.parses(grammar.start()))\n",
    "draw_trees(trees[0][0], trees[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a villager went to city to sell his property along with his wife\n",
      "['a', 'villager', 'went', 'to', 'city', 'to', 'sell', 'his', 'property', 'along', 'with', 'his', 'wife']\n"
     ]
    }
   ],
   "source": [
    "testsentence = \"A villager went to city to sell his property along with his wife\"\n",
    "testsentence = testsentence.lower()\n",
    "print(testsentence)\n",
    "tokens = testsentence.split()\n",
    "print(tokens)\n",
    "grammar2 = nltk.CFG.fromstring(\"\"\"\n",
    "  NP -> DT NN \n",
    "  S ->  NP VP | VP\n",
    "  VP -> VBD PP S | TO VP | VB NP PP\n",
    "  PP -> IN NP |IN PP\n",
    "  NP -> NN | PRP NN |DT NN\n",
    "  DT -> 'a'\n",
    "  NN -> 'villager'\n",
    "  VBD -> 'went' \n",
    "  IN -> 'to' | 'along' | 'with'\n",
    "  NN -> 'city' | 'property' |'wife' \n",
    "  TO -> 'to'\n",
    "  VB -> 'sell'\n",
    "  PRP -> 'his'\n",
    "  \"\"\")\n",
    "parser = nltk.parse.BottomUpLeftCornerChartParser(grammar2)\n",
    "\n",
    "for tree in parser.parse(tokens):\n",
    "    print('entered')\n",
    "    print(tree)\n",
    "    tree.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n"
     ]
    }
   ],
   "source": [
    "print(chart.num_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print((len(list(chart.parses(grammar2.start()))))) #parse trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = list(chart.parses(grammar2.start()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_trees(trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
